# Prompt2Cypher

## Environment Setup

1. Prepare an environment and install packages:
   - `conda create -n prompt2cypher python=3.10`
   - `conda activate prompt2cypher`
   - `pip install -r requirements.txt`
2. Install database in Neo4j
3. Rename `.env.example` to `.env` and update values.

## Benchmarks Reproduction

1. Rename `.env.example` to `.env` and update the values.

1. Only once, or when test queries have changed, run `./src/baseline_cypher_execution.py` to create `./results/<kg>`

1. The `./src/run_benchmarks.py` script generates cypher for user queries, based on the `KG_NAME` value in `.env`.
    > Before running, modify this line of the code if needed: `MODEL_INFO = {"name": "gpt-4o-mini", "filename": "gpt-4o-mini", "litemodel": "gpt-4o-mini",  "is_local": False}`
    - Baseline: `from generate_cypher_baseline import generate_cypher_query as cypher_gen`
    - P2C approach: `from generate_cypher_p2c import generate_cypher_query as cypher_gen`
  
1. The `./src/benchmarks_cypher_execution.py` script runs the cypher queries generated by LLMs. You should change the input json filename, created by the llm in the previous step, in the script.

1. The `./src/calculate_scores_precision_recall.py` script runs benchmarks. You should change the results json filenam (engds with `-with_results.json`)

Only if you need NLP scores (BLEU, ROUGE, ...): Run the `calculate_scores_nlp.py`