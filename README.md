# Prompt2Cypher

## Environment Setup

1. Prepare an environment and install packages:
   - `conda create -n prompt2cypher python=3.10`
   - `conda activate prompt2cypher`
   - `pip install -r requirements.txt`
2. Install database in Neo4j
3. Rename `.env.example` to `.env` and update values.

## Benchmarks Reproduction

1. Rename `.env.example` to `.env` and update the values.

1. Only once, or when test queries have changed, run `./src/baseline_cypher_execution.py` to create `./results/<kg>`

1. The `./src/run_benchmarks.py` script generates cypher for user queries, based on the `KG_NAME` value in `.env`.
    > Before running, modify this line of the code if needed: `MODEL_INFO = {"name": "gpt-4o-mini", "filename": "gpt-4o-mini", "litemodel": "gpt-4o-mini",  "is_local": False}`
    - Baseline: `from generate_cypher_baseline import generate_cypher_query as cypher_gen`
    - P2C approach: `from generate_cypher_p2c import generate_cypher_query as cypher_gen`
  
1. The `./src/benchmarks_cypher_execution.py` script runs the cypher queries generated by LLMs. You should change the input json filename, created by the llm in the previous step, in the script.

1. The `./src/calculate_scores_precision_recall.py` script runs benchmarks. You should change the results json filenam (engds with `-with_results.json`)

Only if you need NLP scores (BLEU, ROUGE, ...): Run the `calculate_scores_nlp.py`

### Ablation
1. `./src/ablation/generate_cypher_ablation.py`: generates cypher by turning on and off different features
1. `./src/ablation/benchmarks_ablation_execution.py`: executes ablations
1. `./src/ablation/calculate_ablation_scores.py`

  Interpretation:
  - Higher values are better for all metrics (range 0-1)
  - Precision: How accurate are the results returned? (% of returned results that are correct)
  - Recall: How complete are the results? (% of expected results that were returned)
  - F1: Balance of precision and recall

  Category-Specific Tables

  The script also breaks down metrics by query categories (e.g., A1, A2, B1, B2 are grouped into "A" and "B" categories):

  Category A:
  +-------------------------+---------------+------------+---------+
  | Ablation Type           | Avg Precision | Avg Recall | Avg F1  |
  +-------------------------+---------------+------------+---------+
  | with_instructions       | 0.9500        | 0.9500     | 0.9500  |
  | without_instructions    | 0.8700        | 0.8300     | 0.8500  |
  | without_schema_comments | 0.6900        | 0.6500     | 0.6700  |
  | without_relevant_nodes  | 0.6000        | 0.5700     | 0.5800  |
  +-------------------------+---------------+------------+---------+

  This helps you understand how each ablation affects different types of queries.
